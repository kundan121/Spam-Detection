{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email Spam Identifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnwiOnGyW5JK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ad515e15-c34c-4335-9fb4-6508531772b5"
      },
      "source": [
        "import csv\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# !wget --no-check-certificate \\\n",
        "    # https://storage.googleapis.com/kagglesdsdata/datasets/483/982/spam.csv \\\n",
        "    # -O /tmp/spam.csv\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPZZ7vmn1lhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install tensorflow --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYo6A4v5ZABQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 1000             # Number of word in local vocabulary\n",
        "embedding_dim = 16\n",
        "max_length = 120              # Maximum length of a sentence in words\n",
        "trunc_type='post'             \n",
        "padding_type='post'          \n",
        "oov_tok = \"<OOV>\"             # Token for unknown words\n",
        "training_portion = .8         # Training Portion .8 means 80% of all data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU1qq3_SZBx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "368f5005-125c-4719-eda1-33732c2df85f"
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "# stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "stopwords = set(stopwords.words('english')) \n",
        "print(len(stopwords))              # List of words that have no weightage for email being spam or non-spam\n",
        "# Expected Output\n",
        "# 153"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eutB2xMiZD0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "85773fae-7a90-49a2-a8de-3c351a81c94c"
      },
      "source": [
        "with open(\"/tmp/spam.csv\", 'r', encoding='ISO 8859-1') as csvfile: # Read csv file and pass through stopwords\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        labels.append(row[0])\n",
        "        sentence = row[1]\n",
        "        for word in stopwords:\n",
        "            token = \" \" + word + \" \"\n",
        "            sentence = sentence.replace(token, \" \")\n",
        "        sentences.append(sentence)\n",
        "\n",
        "print(len(labels))\n",
        "print(len(sentences))\n",
        "print(sentences[0])\n",
        "# Actual sentence[0] in csv is    -     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
        "# But it would be printed a little bit different as all data passes through stopwords"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5572\n",
            "5572\n",
            "Go jurong point, crazy.. Available bugis n great world la e buffet... Cine got amore wat...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfdaWh06ZGe3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9c989ca1-0412-4dfa-b99d-db895b899c17"
      },
      "source": [
        "train_size = int(len(sentences) * training_portion)\n",
        "\n",
        "train_sentences = sentences[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "validation_sentences = sentences[train_size:]\n",
        "validation_labels = labels[train_size:]\n",
        "\n",
        "print(train_size)\n",
        "print(len(train_sentences))\n",
        "print(len(train_labels))\n",
        "print(len(validation_sentences))\n",
        "print(len(validation_labels))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4457\n",
            "4457\n",
            "4457\n",
            "1115\n",
            "1115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULzA8xhwZI22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8PeFWzPZLW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
        "validation_padded = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkWiQ_FKZNp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(labels)\n",
        "\n",
        "training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
        "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ5um4MWZP-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "459f063a-c298-41c5-907a-e4b63a1f933c"
      },
      "source": [
        "# Create a RNN Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 120, 16)           16000     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 150       \n",
            "=================================================================\n",
            "Total params: 16,558\n",
            "Trainable params: 16,558\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsfdxySKZSXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c40f6f0e-b190-493f-90af-9b171aac3d2f"
      },
      "source": [
        "num_epochs = 50                    # number of epochs\n",
        "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4457 samples, validate on 1115 samples\n",
            "Epoch 1/50\n",
            "4457/4457 - 1s - loss: 1.1466 - accuracy: 0.8185 - val_loss: 0.4470 - val_accuracy: 0.8700\n",
            "Epoch 2/50\n",
            "4457/4457 - 1s - loss: 0.4041 - accuracy: 0.8649 - val_loss: 0.3700 - val_accuracy: 0.8700\n",
            "Epoch 3/50\n",
            "4457/4457 - 1s - loss: 0.3697 - accuracy: 0.8649 - val_loss: 0.3495 - val_accuracy: 0.8700\n",
            "Epoch 4/50\n",
            "4457/4457 - 1s - loss: 0.3491 - accuracy: 0.8649 - val_loss: 0.3266 - val_accuracy: 0.8700\n",
            "Epoch 5/50\n",
            "4457/4457 - 1s - loss: 0.3204 - accuracy: 0.8647 - val_loss: 0.2902 - val_accuracy: 0.8691\n",
            "Epoch 6/50\n",
            "4457/4457 - 1s - loss: 0.2648 - accuracy: 0.8687 - val_loss: 0.2190 - val_accuracy: 0.8933\n",
            "Epoch 7/50\n",
            "4457/4457 - 1s - loss: 0.1885 - accuracy: 0.9228 - val_loss: 0.1469 - val_accuracy: 0.9570\n",
            "Epoch 8/50\n",
            "4457/4457 - 1s - loss: 0.1313 - accuracy: 0.9605 - val_loss: 0.1079 - val_accuracy: 0.9695\n",
            "Epoch 9/50\n",
            "4457/4457 - 1s - loss: 0.0995 - accuracy: 0.9684 - val_loss: 0.0906 - val_accuracy: 0.9731\n",
            "Epoch 10/50\n",
            "4457/4457 - 1s - loss: 0.0815 - accuracy: 0.9746 - val_loss: 0.0743 - val_accuracy: 0.9767\n",
            "Epoch 11/50\n",
            "4457/4457 - 1s - loss: 0.0690 - accuracy: 0.9780 - val_loss: 0.0650 - val_accuracy: 0.9794\n",
            "Epoch 12/50\n",
            "4457/4457 - 1s - loss: 0.0593 - accuracy: 0.9816 - val_loss: 0.0593 - val_accuracy: 0.9803\n",
            "Epoch 13/50\n",
            "4457/4457 - 1s - loss: 0.0536 - accuracy: 0.9854 - val_loss: 0.0522 - val_accuracy: 0.9794\n",
            "Epoch 14/50\n",
            "4457/4457 - 1s - loss: 0.0469 - accuracy: 0.9870 - val_loss: 0.0516 - val_accuracy: 0.9821\n",
            "Epoch 15/50\n",
            "4457/4457 - 1s - loss: 0.0437 - accuracy: 0.9870 - val_loss: 0.0467 - val_accuracy: 0.9830\n",
            "Epoch 16/50\n",
            "4457/4457 - 1s - loss: 0.0397 - accuracy: 0.9888 - val_loss: 0.0448 - val_accuracy: 0.9821\n",
            "Epoch 17/50\n",
            "4457/4457 - 1s - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.0429 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "4457/4457 - 1s - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.0423 - val_accuracy: 0.9821\n",
            "Epoch 19/50\n",
            "4457/4457 - 1s - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.0423 - val_accuracy: 0.9830\n",
            "Epoch 20/50\n",
            "4457/4457 - 1s - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.0402 - val_accuracy: 0.9848\n",
            "Epoch 21/50\n",
            "4457/4457 - 1s - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
            "Epoch 22/50\n",
            "4457/4457 - 1s - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.0407 - val_accuracy: 0.9839\n",
            "Epoch 23/50\n",
            "4457/4457 - 1s - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0429 - val_accuracy: 0.9848\n",
            "Epoch 24/50\n",
            "4457/4457 - 1s - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0391 - val_accuracy: 0.9857\n",
            "Epoch 25/50\n",
            "4457/4457 - 1s - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.0418 - val_accuracy: 0.9848\n",
            "Epoch 26/50\n",
            "4457/4457 - 1s - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0403 - val_accuracy: 0.9865\n",
            "Epoch 27/50\n",
            "4457/4457 - 1s - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
            "Epoch 28/50\n",
            "4457/4457 - 1s - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.0458 - val_accuracy: 0.9857\n",
            "Epoch 29/50\n",
            "4457/4457 - 1s - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
            "Epoch 30/50\n",
            "4457/4457 - 1s - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0393 - val_accuracy: 0.9874\n",
            "Epoch 31/50\n",
            "4457/4457 - 1s - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0399 - val_accuracy: 0.9874\n",
            "Epoch 32/50\n",
            "4457/4457 - 1s - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0400 - val_accuracy: 0.9874\n",
            "Epoch 33/50\n",
            "4457/4457 - 1s - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.0407 - val_accuracy: 0.9857\n",
            "Epoch 34/50\n",
            "4457/4457 - 1s - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0409 - val_accuracy: 0.9883\n",
            "Epoch 35/50\n",
            "4457/4457 - 1s - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0406 - val_accuracy: 0.9874\n",
            "Epoch 36/50\n",
            "4457/4457 - 1s - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0410 - val_accuracy: 0.9865\n",
            "Epoch 37/50\n",
            "4457/4457 - 1s - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0418 - val_accuracy: 0.9865\n",
            "Epoch 38/50\n",
            "4457/4457 - 1s - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.0421 - val_accuracy: 0.9874\n",
            "Epoch 39/50\n",
            "4457/4457 - 1s - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.0425 - val_accuracy: 0.9883\n",
            "Epoch 40/50\n",
            "4457/4457 - 1s - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0437 - val_accuracy: 0.9865\n",
            "Epoch 41/50\n",
            "4457/4457 - 1s - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
            "Epoch 42/50\n",
            "4457/4457 - 1s - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0455 - val_accuracy: 0.9892\n",
            "Epoch 43/50\n",
            "4457/4457 - 1s - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
            "Epoch 44/50\n",
            "4457/4457 - 1s - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
            "Epoch 45/50\n",
            "4457/4457 - 1s - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0478 - val_accuracy: 0.9892\n",
            "Epoch 46/50\n",
            "4457/4457 - 1s - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0489 - val_accuracy: 0.9892\n",
            "Epoch 47/50\n",
            "4457/4457 - 1s - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0481 - val_accuracy: 0.9883\n",
            "Epoch 48/50\n",
            "4457/4457 - 1s - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
            "Epoch 49/50\n",
            "4457/4457 - 1s - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
            "Epoch 50/50\n",
            "4457/4457 - 1s - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0497 - val_accuracy: 0.9883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U_ym5cx_iGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fecfd50-554e-486e-aaf7-c9b9e3ec9280"
      },
      "source": [
        "test_sentences = [\"WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\",\n",
        "                  \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"]\n",
        "for sentence in test_sentences:\n",
        "    for word in stopwords:\n",
        "        token = \" \" + word + \" \"\n",
        "        sentence = sentence.replace(token, \" \")\n",
        "test_sentences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sentences, padding=padding_type, maxlen=max_length)\n",
        "predict_mail = model.predict_classes(test_padded)\n",
        "print(predict_mail)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzfamwl1RmzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}